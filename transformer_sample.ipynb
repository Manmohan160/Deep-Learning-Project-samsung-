{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12034564,"sourceType":"datasetVersion","datasetId":7572360}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#define your parameters here\n#used reference from here: https://www.kaggle.com/code/prakharbatwal/transformer\npretrained_model = 'bert-base-uncased'\nnum_epochs = 3\nlearning_rate = 5e-5\nbatch_size = 8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:21:10.356000Z","iopub.execute_input":"2025-06-06T15:21:10.356686Z","iopub.status.idle":"2025-06-06T15:21:10.360339Z","shell.execute_reply.started":"2025-06-06T15:21:10.356656Z","shell.execute_reply":"2025-06-06T15:21:10.359621Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\n\nif(torch.cuda.is_available()):\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\n\nprint(f\"using {device} for processing\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:32:14.796051Z","iopub.execute_input":"2025-06-06T15:32:14.796424Z","iopub.status.idle":"2025-06-06T15:32:14.801077Z","shell.execute_reply.started":"2025-06-06T15:32:14.796397Z","shell.execute_reply":"2025-06-06T15:32:14.800457Z"}},"outputs":[{"name":"stdout","text":"using cuda for processing\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd;import numpy as np\ndf = pd.read_csv(\"/kaggle/input/raw-news/news.csv\")\ndf.drop_duplicates(subset='text', inplace=True)\ndf.dropna(subset=['text', 'label'], inplace=True)\ndf = df[df['text'].str.strip() != \"\"]\nfrom sklearn.utils import shuffle\ndf = shuffle(df, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:04:04.100085Z","iopub.execute_input":"2025-06-06T15:04:04.100561Z","iopub.status.idle":"2025-06-06T15:04:09.360245Z","shell.execute_reply.started":"2025-06-06T15:04:04.100535Z","shell.execute_reply":"2025-06-06T15:04:09.359527Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df['text'].tolist()\ny = df['label'].tolist()\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:05:50.275755Z","iopub.execute_input":"2025-06-06T15:05:50.276531Z","iopub.status.idle":"2025-06-06T15:05:50.398481Z","shell.execute_reply.started":"2025-06-06T15:05:50.276501Z","shell.execute_reply":"2025-06-06T15:05:50.397916Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"type(y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:05:51.285740Z","iopub.execute_input":"2025-06-06T15:05:51.286475Z","iopub.status.idle":"2025-06-06T15:05:51.291676Z","shell.execute_reply.started":"2025-06-06T15:05:51.286447Z","shell.execute_reply":"2025-06-06T15:05:51.290955Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"list"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"print(\"Train Label Counts:\", pd.Series(y_train).value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:05:52.782486Z","iopub.execute_input":"2025-06-06T15:05:52.782750Z","iopub.status.idle":"2025-06-06T15:05:52.800923Z","shell.execute_reply.started":"2025-06-06T15:05:52.782730Z","shell.execute_reply":"2025-06-06T15:05:52.800171Z"}},"outputs":[{"name":"stdout","text":"Train Label Counts: 1    16983\n0    13932\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n\ntrain_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=256,return_tensors=\"pt\").to(device)\ntest_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=256,return_tensors=\"pt\").to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:33:23.868868Z","iopub.execute_input":"2025-06-06T15:33:23.869425Z","iopub.status.idle":"2025-06-06T15:33:55.767585Z","shell.execute_reply.started":"2025-06-06T15:33:23.869402Z","shell.execute_reply":"2025-06-06T15:33:55.766955Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import torch\n\nclass NewsDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = NewsDataset(train_encodings, y_train)\ntest_dataset = NewsDataset(test_encodings, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:34:27.699962Z","iopub.execute_input":"2025-06-06T15:34:27.700528Z","iopub.status.idle":"2025-06-06T15:34:28.765450Z","shell.execute_reply.started":"2025-06-06T15:34:27.700505Z","shell.execute_reply":"2025-06-06T15:34:28.764622Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_dataset = NewsDataset(train_encodings, y_train)\ntest_dataset = NewsDataset(test_encodings, y_test)\ntrain_dataset.__getitem__(1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:34:32.076082Z","iopub.execute_input":"2025-06-06T15:34:32.076389Z","iopub.status.idle":"2025-06-06T15:34:32.097476Z","shell.execute_reply.started":"2025-06-06T15:34:32.076364Z","shell.execute_reply":"2025-06-06T15:34:32.096772Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2811690718.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([  101, 13229,  2763, 20010,  4355,  2015,  6926,  8845,  2040, 13950,\n          2068,  2006,  2037, 21882,  7088,  5289,  2015,  8275,  2739,  9499,\n           999,  3422,  1996,  2678,  1998,  2156,  2129,  1996, 13229,  6443,\n          3269,  2048, 12060,  2157,  2279,  2000,  2169,  2060,  2021,  1037,\n         28988,  2008, 12271,  2083,  1996,  2915, 13950,  2015,  2068,  2006,\n          2037,  3975,  8040,  4402,  2368,  8275,  2739,  2693,  2664,  2178,\n         18932,  1997, 21699,  1001,  8275,  2638,  9333,  2004,  1001,  8275,\n          2638,  9333,  2278, 10695,  3594,  1037,  3975,  3898,  2005, 12060,\n          3061,  2157,  2279,  2000,  2169,  2060,   999,  1001, 23848,  2050,\n         27263,  1012, 10474,  1012,  4012,  1013,  1062, 26291, 16257,  5705,\n          2100,  5666,  8398, 19454, 24612,  1006,  1030,  4913,  4890,  5737,\n          6137,  1007,  2281,  1016,  1010,  2418,  8545,  2310,  3139,  2060,\n          8275,  2739,  5312,  2013, 13229,  3342,  2023,  1029, 13229,  3236,\n         15308,  8275,  6186,  2012,  2414,  2958,  3143,  2007,  5152, 12954,\n          2015,  4597,  1010,  4950,  1010,  2895,   999, 13229,  2699,  2000,\n          9922,  1037,  3496,  1997,  3424,  1011, 18301,  6186,  2011,  2070,\n          5152, 12954,  2015,  2021,  3478,  1012,  2017,  2064,  2963,  2111,\n          5870,  2125,  4950,  2875,  1996,  2203,  1997,  1996,  2678,  1012,\n          2017,  2064,  2156,  2329,  2865,  1998, 13229, 11370, 14407,  5143,\n         15308,  1996, 10398,  2005,  1996,  4378,  1012,  2009,  1055,  5621,\n          5305,  7406,  2000,  2156,  1996,  6698,  2027,  2097,  2175,  2000,\n          5245,  1996,  6270,  7984,  2008,  2122,  5152, 12954,  2015,  2020,\n          2045,  2077,  1996,  8629,  2288,  2045,   999,  4895, 22852,   999,\n          2009,  1055,  2035,  9813,   999,  1996,  2865,  2038,  2025,  2069,\n          2468,  1037,  5195,  1997,  8801,  2021,  1037, 10398,  3698,  2000,\n          4338,  1996,  7984,  1997,  2074,   102], device='cuda:0'),\n 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n 'labels': tensor(0)}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"for i in range(5):\n    sample = train_dataset[i]\n    print(f\"Label: {sample['labels']}, Decoded: {tokenizer.decode(sample['input_ids'])[:100]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:34:44.057944Z","iopub.execute_input":"2025-06-06T15:34:44.058224Z","iopub.status.idle":"2025-06-06T15:34:44.067450Z","shell.execute_reply.started":"2025-06-06T15:34:44.058204Z","shell.execute_reply":"2025-06-06T15:34:44.066721Z"}},"outputs":[{"name":"stdout","text":"Label: 0, Decoded: [CLS] president trump told the graduates that they are graduating to a totally brilliant future. tru\nLabel: 1, Decoded: [CLS] moscow ( reuters ) - russia designated radio free europe / radio liberty ( rfe / rl ) and voic\nLabel: 0, Decoded: [CLS] after hillary clinton made the argument that donald trump s hateful rants against muslims were\nLabel: 1, Decoded: [CLS] new york ( reuters ) - u. s. presidential candidate hillary clinton ’ s spokeswoman said on fr\nLabel: 1, Decoded: [CLS] harare ( reuters ) - retired army chief constantino chiwenga and veteran politician kembo moha\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/2811690718.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(type(train_encodings))\nprint(train_encodings.keys())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:34:45.605556Z","iopub.execute_input":"2025-06-06T15:34:45.606255Z","iopub.status.idle":"2025-06-06T15:34:45.610082Z","shell.execute_reply.started":"2025-06-06T15:34:45.606223Z","shell.execute_reply":"2025-06-06T15:34:45.609474Z"}},"outputs":[{"name":"stdout","text":"<class 'transformers.tokenization_utils_base.BatchEncoding'>\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"sample = train_dataset.__getitem__(1)\nprint(\"Keys:\", sample.keys())\nprint(\"Input IDs:\", sample[\"input_ids\"][:10])  # Show first 10 tokens\nprint(\"Label:\", sample[\"labels\"])\nprint(\"Decoded:\", tokenizer.decode(sample[\"input_ids\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:34:58.662783Z","iopub.execute_input":"2025-06-06T15:34:58.663411Z","iopub.status.idle":"2025-06-06T15:34:58.670185Z","shell.execute_reply.started":"2025-06-06T15:34:58.663389Z","shell.execute_reply":"2025-06-06T15:34:58.669355Z"}},"outputs":[{"name":"stdout","text":"Keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\nInput IDs: tensor([  101,  4924,  1006, 26665,  1007,  1011,  3607,  4351,  2557,  2489],\n       device='cuda:0')\nLabel: tensor(1)\nDecoded: [CLS] moscow ( reuters ) - russia designated radio free europe / radio liberty ( rfe / rl ) and voice of america ( voa ) as foreign agents on tuesday, a move aimed at complicating their work in retaliation for what moscow says is unacceptable u. s. pressure on russian media. russia s broadside is likely to further sour battered u. s. - russia relations and is part of the fallout from allegations that the kremlin meddled in the u. s. presidential election last year in donald trump s favor, something moscow denies. u. s. intelligence officials accused the kremlin of using russian media it finances to influence u. s. voters, and russian state broadcaster rt last month reluctantly complied with a u. s. request to register a u. s. - based affiliate as a foreign agent under the foreign agent registration act. the kremlin called the move an attack on free speech and says the new media law in russia, which western critics have called a disproportionate response, is retaliation. moscow s response was widely trailed. russian lawmakers rushed through the necessary legislation last month and president vladimir putin signed off on it on nov. 25. russia s justice ministry said in a statement on its website [SEP]\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/2811690718.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nmodel = AutoModelForSequenceClassification.from_pretrained(pretrained_model, num_labels=2).to(device)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\", #saves the model after every epoch into the out directory\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=num_epochs,\n    learning_rate = learning_rate,\n    gradient_accumulation_steps=1,\n    fp16=True,\n    report_to=\"none\",\n    dataloader_pin_memory=True if device == \"cpu\" else False\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset\n)\nprint(\"Train size:\", len(train_dataset))\nprint(\"Test size:\", len(test_dataset))\n\n# Sanity check random entries\nprint(\"Sample train label:\", y_train[0])\nprint(\"Sample test label:\", y_test[0])\nprint(\"Sample train text:\", X_train[0][:300])  # preview first 300 chars\nprint(\"Sample test text:\", X_test[0][:300])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:38:48.429660Z","iopub.execute_input":"2025-06-06T15:38:48.429946Z","iopub.status.idle":"2025-06-06T15:38:48.944885Z","shell.execute_reply.started":"2025-06-06T15:38:48.429928Z","shell.execute_reply":"2025-06-06T15:38:48.944018Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Train size: 30915\nTest size: 7729\nSample train label: 0\nSample test label: 1\nSample train text: President Trump told the graduates that they are  graduating to a totally brilliant future. Trump specifically recognized graduates who have served in the military,  It is truly a testament to this university and to the values that you embrace, that your graduating class includes so many patriots wh\nSample test text: LONDON (Reuters) - A British government official cast doubt on a newspaper report on Tuesday that Britain and the EU had reached a financial settlement of between 45 billion and 55 billion euros.  I do not recognize this account of the negotiations,  said the government official, who declined to be \n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"model.device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:38:52.487892Z","iopub.execute_input":"2025-06-06T15:38:52.488617Z","iopub.status.idle":"2025-06-06T15:38:52.493204Z","shell.execute_reply.started":"2025-06-06T15:38:52.488592Z","shell.execute_reply":"2025-06-06T15:38:52.492634Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"trainer.train()\ntrainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T15:38:54.932080Z","iopub.execute_input":"2025-06-06T15:38:54.932418Z","iopub.status.idle":"2025-06-06T16:22:19.753702Z","shell.execute_reply.started":"2025-06-06T15:38:54.932395Z","shell.execute_reply":"2025-06-06T16:22:19.753046Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2811690718.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='11595' max='11595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [11595/11595 42:27, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.000100</td>\n      <td>0.001324</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.001565</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000000</td>\n      <td>0.001259</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_35/2811690718.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_35/2811690718.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_35/2811690718.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.001259368029423058,\n 'eval_runtime': 56.4399,\n 'eval_samples_per_second': 136.942,\n 'eval_steps_per_second': 17.133,\n 'epoch': 3.0}"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\n\n\npreds = trainer.predict(test_dataset)\nprint(\"Raw logits for first 5 samples:\\n\", preds.predictions[:5])\n\ny_pred = np.argmax(preds.predictions, axis=1)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T16:22:31.109775Z","iopub.execute_input":"2025-06-06T16:22:31.110521Z","iopub.status.idle":"2025-06-06T16:23:29.462916Z","shell.execute_reply.started":"2025-06-06T16:22:31.110499Z","shell.execute_reply":"2025-06-06T16:23:29.462299Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2811690718.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"name":"stdout","text":"Raw logits for first 5 samples:\n [[-6.0351562  6.6992188]\n [ 6.25      -6.8789062]\n [ 6.2460938 -6.859375 ]\n [ 6.2226562 -6.9101562]\n [-6.0351562  6.703125 ]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      3521\n           1       1.00      1.00      1.00      4208\n\n    accuracy                           1.00      7729\n   macro avg       1.00      1.00      1.00      7729\nweighted avg       1.00      1.00      1.00      7729\n\n[[3521    0]\n [   1 4207]]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import torch\n\nrandom_texts = [\"this is gibberish\", \"you won a lottery\", \"election results\"]\ninputs = tokenizer(random_texts, return_tensors=\"pt\", truncation=True, padding=True)\n\n# Move inputs to model's device (usually cuda:0)\ndevice = model.device\ninputs = {k: v.to(device) for k, v in inputs.items()}\n\n# Predict\noutputs = model(**inputs)\npreds = torch.argmax(outputs.logits, axis=1)\nprint(preds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T16:23:41.225514Z","iopub.execute_input":"2025-06-06T16:23:41.225791Z","iopub.status.idle":"2025-06-06T16:23:41.268190Z","shell.execute_reply.started":"2025-06-06T16:23:41.225773Z","shell.execute_reply":"2025-06-06T16:23:41.267442Z"}},"outputs":[{"name":"stdout","text":"tensor([0, 0, 0], device='cuda:0')\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}