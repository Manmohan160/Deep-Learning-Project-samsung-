{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12095310,"sourceType":"datasetVersion","datasetId":7614282},{"sourceId":12095322,"sourceType":"datasetVersion","datasetId":7614292}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from torchtext.data.utils import get_tokenizer\n# from torchtext.vocab import build_vocab_from_iterator\nfrom transformers import AutoTokenizer\nfrom transformers import MarianMTModel, MarianTokenizer\nfrom typing import Iterable, List\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader, Dataset\nfrom timeit import default_timer as timer\nfrom torch.nn import Transformer\nfrom torch import Tensor\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nimport torch.nn as nn\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport math\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport json","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:22:19.017566Z","iopub.execute_input":"2025-06-09T14:22:19.017765Z","iopub.status.idle":"2025-06-09T14:22:46.309840Z","shell.execute_reply.started":"2025-06-09T14:22:19.017748Z","shell.execute_reply":"2025-06-09T14:22:46.309213Z"}},"outputs":[{"name":"stderr","text":"2025-06-09 14:22:33.909061: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749478954.191770      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749478954.257304      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Set seed.\nseed = 42\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:22:53.140472Z","iopub.execute_input":"2025-06-09T14:22:53.141136Z","iopub.status.idle":"2025-06-09T14:22:53.150158Z","shell.execute_reply.started":"2025-06-09T14:22:53.141114Z","shell.execute_reply":"2025-06-09T14:22:53.149395Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"SRC_LANGUAGE = 'ko'\nTGT_LANGUAGE = 'en'\n# src_model_checkpoint = 'distilbert-base-cased'\n# tgt_model_checkpoint = \"klue/bert-base\"\n\nmodel_name = \"Helsinki-NLP/opus-mt-ko-en\"\n\ntraining_file_path = \"/kaggle/input/sampledataset/sampleData.json\"\ncols = [\"ko_text\", \"en_text\"]\n\ntest_size = 0.25\n\nBATCH_SIZE = 1\nNUM_EPOCHS = 2\nif(torch.cuda.is_available()):\n    DEVICE = \"cuda\"\nelse:\n    DEVICE = \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:22:55.152586Z","iopub.execute_input":"2025-06-09T14:22:55.153154Z","iopub.status.idle":"2025-06-09T14:22:55.158261Z","shell.execute_reply.started":"2025-06-09T14:22:55.153130Z","shell.execute_reply":"2025-06-09T14:22:55.157497Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"token_transformer = MarianTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:22:58.915203Z","iopub.execute_input":"2025-06-09T14:22:58.915462Z","iopub.status.idle":"2025-06-09T14:23:00.529079Z","shell.execute_reply.started":"2025-06-09T14:22:58.915445Z","shell.execute_reply":"2025-06-09T14:23:00.528240Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50b04d44bffa402a9618be1713eafcf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/842k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29e31ba3ad4a4314873bad8e02b2e005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/813k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"798e56bf5bb04f33bc4f94a83d453a36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42937926bc3b4e7a8a36a4c6cbf951c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39728616f10846f69e2389d68ae13fd0"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"token_transformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:23:03.772751Z","iopub.execute_input":"2025-06-09T14:23:03.773264Z","iopub.status.idle":"2025-06-09T14:23:03.778176Z","shell.execute_reply.started":"2025-06-09T14:23:03.773240Z","shell.execute_reply":"2025-06-09T14:23:03.777472Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-ko-en', vocab_size=65001, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t65000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}\n)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# json_data = json.load(training_file_path)\nwith open(training_file_path, encoding = 'utf-8') as f:\n    json_data = json.load(f)\n# json_data\ntexts = [{col: item[col] for col in cols} for item in json_data[\"Text\"]]\n\ndf = pd.DataFrame(texts)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:23:06.341330Z","iopub.execute_input":"2025-06-09T14:23:06.341618Z","iopub.status.idle":"2025-06-09T14:23:06.370577Z","shell.execute_reply.started":"2025-06-09T14:23:06.341598Z","shell.execute_reply":"2025-06-09T14:23:06.369757Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                             ko_text  \\\n0  아내가 외출하기 전 끓여놓은 국과 반찬을 식판에 떠서 먹이기만 하면 되는데 말처럼 ...   \n1                매번 잘 차려진 밥상에 숟가락만 들었던 내 모습이 부끄러워진다.   \n2  가끔 평일에 일찍 들어가 가족들과 밥을 먹을 때 왜 아내가 그렇게 아이들에게 고함을...   \n3  분명 아이들 밥을 차린 시간은 5분이 채 되지 않았는데, 아침식사 시간은 한 시간이...   \n\n                                             en_text  \n0  What needs to be done is to scoop up the boile...  \n1  I'm ashamed of myself for holding only a spoon...  \n2  Sometimes when I got home early on weekdays an...  \n3  It has been less than 5 minutes since the chil...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ko_text</th>\n      <th>en_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>아내가 외출하기 전 끓여놓은 국과 반찬을 식판에 떠서 먹이기만 하면 되는데 말처럼 ...</td>\n      <td>What needs to be done is to scoop up the boile...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>매번 잘 차려진 밥상에 숟가락만 들었던 내 모습이 부끄러워진다.</td>\n      <td>I'm ashamed of myself for holding only a spoon...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>가끔 평일에 일찍 들어가 가족들과 밥을 먹을 때 왜 아내가 그렇게 아이들에게 고함을...</td>\n      <td>Sometimes when I got home early on weekdays an...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>분명 아이들 밥을 차린 시간은 5분이 채 되지 않았는데, 아침식사 시간은 한 시간이...</td>\n      <td>It has been less than 5 minutes since the chil...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"train_data, test_data = train_test_split(df, test_size = test_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:23:09.025427Z","iopub.execute_input":"2025-06-09T14:23:09.025720Z","iopub.status.idle":"2025-06-09T14:23:09.036845Z","shell.execute_reply.started":"2025-06-09T14:23:09.025677Z","shell.execute_reply":"2025-06-09T14:23:09.036079Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Custom Dataset class.\nclass TranslationDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length = 128):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        src = self.df[cols[0]].iloc[idx]\n        tgt = self.df[cols[1]].iloc[idx]\n\n        src_enc = self.tokenizer(src, return_tensors = \"pt\", padding=\"max_length\", truncation=True, max_length = self.max_length)\n        tgt_enc = self.tokenizer(tgt, return_tensors = \"pt\", padding=\"max_length\", truncation=True, max_length = self.max_length)\n\n        input_ids = src_enc[\"input_ids\"].squeeze()\n        attention_mask = src_enc[\"attention_mask\"].squeeze()\n        labels = tgt_enc[\"input_ids\"].squeeze()\n        labels[labels == self.tokenizer.pad_token_id] = -100 #ignore padding in loss calculation\n        return{\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            \"labels\":labels\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:23:11.760003Z","iopub.execute_input":"2025-06-09T14:23:11.760503Z","iopub.status.idle":"2025-06-09T14:23:11.766534Z","shell.execute_reply.started":"2025-06-09T14:23:11.760479Z","shell.execute_reply":"2025-06-09T14:23:11.765737Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_dataset = TranslationDataset(train_data, token_transformer)\nvalid_dataset = TranslationDataset(test_data, token_transformer)\niterator = iter(train_dataset)\nprint(next(iterator))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:23:14.378274Z","iopub.execute_input":"2025-06-09T14:23:14.378986Z","iopub.status.idle":"2025-06-09T14:23:14.398906Z","shell.execute_reply.started":"2025-06-09T14:23:14.378961Z","shell.execute_reply":"2025-06-09T14:23:14.398258Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': tensor([ 1937, 14270,  8189,    51,  1643,  1412, 15645,   309, 12068,  4827,\n         4491, 39711,     3,     9, 39027, 15645,    54,  2660,  5795, 15856,\n            9, 48114,     2,     0, 65000, 65000, 65000, 65000, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([   91,  3963,  2025,    31,  1252,  4874, 10705,  2718, 12081,   309,\n            9,  7613, 14542,    10,  1280,  4735,     4, 18923, 28907,   101,\n          649,    12,    10,    75,   639,    35,  1835,   101,  8816,  7405,\n            3,    99,   575,   101,  8526,  1931, 20861,  2718, 13502,    10,\n          132,  3963,  5224,     5,    31,   190,   457,     2,     0,  -100,\n         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model = MarianMTModel.from_pretrained(model_name).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:23:17.540346Z","iopub.execute_input":"2025-06-09T14:23:17.540623Z","iopub.status.idle":"2025-06-09T14:23:21.068831Z","shell.execute_reply.started":"2025-06-09T14:23:17.540601Z","shell.execute_reply":"2025-06-09T14:23:21.067740Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cd28768bfa7498aa9f2a9ea9d0cf168"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd5f7c7d74924b5483a830692abd8418"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/312M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6aa65e8f8cc4cee9ac68cd26ab1ab5a"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Total parameters and trainable parameters.\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"{total_params:,} total parameters.\")\ntotal_trainable_params = sum(\n    p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"{total_trainable_params:,} training parameters.\")\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:23:54.270867Z","iopub.execute_input":"2025-06-09T14:23:54.271394Z","iopub.status.idle":"2025-06-09T14:23:54.279017Z","shell.execute_reply.started":"2025-06-09T14:23:54.271371Z","shell.execute_reply":"2025-06-09T14:23:54.277562Z"}},"outputs":[{"name":"stdout","text":"77,943,296 total parameters.\n77,943,296 training parameters.\nMarianMTModel(\n  (model): MarianModel(\n    (shared): Embedding(65001, 512, padding_idx=65000)\n    (encoder): MarianEncoder(\n      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLU()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (decoder): MarianDecoder(\n      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLU()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:23:59.844069Z","iopub.execute_input":"2025-06-09T14:23:59.844623Z","iopub.status.idle":"2025-06-09T14:23:59.849161Z","shell.execute_reply.started":"2025-06-09T14:23:59.844599Z","shell.execute_reply":"2025-06-09T14:23:59.848453Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:24:05.276701Z","iopub.execute_input":"2025-06-09T14:24:05.276964Z","iopub.status.idle":"2025-06-09T14:24:05.280891Z","shell.execute_reply.started":"2025-06-09T14:24:05.276946Z","shell.execute_reply":"2025-06-09T14:24:05.280248Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:24:07.826705Z","iopub.execute_input":"2025-06-09T14:24:07.827419Z","iopub.status.idle":"2025-06-09T14:24:07.835757Z","shell.execute_reply.started":"2025-06-09T14:24:07.827395Z","shell.execute_reply":"2025-06-09T14:24:07.835013Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([ 1937, 14270,  8189,    51,  1643,  1412, 15645,   309, 12068,  4827,\n          4491, 39711,     3,     9, 39027, 15645,    54,  2660,  5795, 15856,\n             9, 48114,     2,     0, 65000, 65000, 65000, 65000, 65000, 65000,\n         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n 'labels': tensor([   91,  3963,  2025,    31,  1252,  4874, 10705,  2718, 12081,   309,\n             9,  7613, 14542,    10,  1280,  4735,     4, 18923, 28907,   101,\n           649,    12,    10,    75,   639,    35,  1835,   101,  8816,  7405,\n             3,    99,   575,   101,  8526,  1931, 20861,  2718, 13502,    10,\n           132,  3963,  5224,     5,    31,   190,   457,     2,     0,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"model_name = \"Helsinki-NLP/opus-mt-ko-en\"\ntokenizer = MarianTokenizer.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name)\n\nsrc_text = [\"안녕하세요. 만나서 반갑습니다.\"]\ninputs = tokenizer(src_text, return_tensors=\"pt\", padding=True)\n\ninputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:24:10.896768Z","iopub.execute_input":"2025-06-09T14:24:10.897033Z","iopub.status.idle":"2025-06-09T14:24:11.734860Z","shell.execute_reply.started":"2025-06-09T14:24:10.897015Z","shell.execute_reply":"2025-06-09T14:24:11.734267Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[ 4192,     2, 12299, 33891,     2,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\ndef train(model, optimizer, num_epochs, dataloader):\n    print('Training')\n    model.to(DEVICE)\n    model.train()\n\n    train_loss = []\n    for epoch in range(num_epochs):\n        epoch_loss = 0\n        num_iter = 0\n        for batch in dataloader:\n            input_ids = torch.tensor(batch['input_ids']).to(DEVICE)\n            attention_mask = torch.tensor(batch['attention_mask']).to(DEVICE)\n            labels = torch.tensor(batch['labels']).to(DEVICE)\n    \n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n\n            epoch_loss += loss.item()\n            num_iter += 1\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            print(f\"Epoch {epoch}, iter = {num_iter}, Loss: {loss.item()}\")\n        train_loss.append(epoch_loss/num_iter)\n    return train_loss\n\ndef evaluate(model, dataloader):\n    print('Validating')\n    model.eval()\n    losses = 0\n    num_iter = 0\n    # valid_loss = []\n    for batch in dataloader:\n        input_ids = torch.tensor(batch['input_ids']).to(DEVICE)\n        attention_mask = torch.tensor(batch['attention_mask']).to(DEVICE)\n        labels = torch.tensor(batch['labels']).to(DEVICE)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n\n        losses += loss.item()\n        num_iter += 1\n        print(f\"iter = {num_iter}, Loss: {loss.item()}\")\n    # valid_loss.append(epoch_loss/num_iter)\n    return losses/num_iter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:24:15.330238Z","iopub.execute_input":"2025-06-09T14:24:15.330746Z","iopub.status.idle":"2025-06-09T14:24:15.337810Z","shell.execute_reply.started":"2025-06-09T14:24:15.330721Z","shell.execute_reply":"2025-06-09T14:24:15.337035Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train(model, optimizer, NUM_EPOCHS, train_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:24:18.117023Z","iopub.execute_input":"2025-06-09T14:24:18.117575Z","iopub.status.idle":"2025-06-09T14:24:19.044352Z","shell.execute_reply.started":"2025-06-09T14:24:18.117550Z","shell.execute_reply":"2025-06-09T14:24:19.043798Z"}},"outputs":[{"name":"stdout","text":"Training\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/4112800121.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  input_ids = torch.tensor(batch['input_ids']).to(DEVICE)\n/tmp/ipykernel_35/4112800121.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  attention_mask = torch.tensor(batch['attention_mask']).to(DEVICE)\n/tmp/ipykernel_35/4112800121.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(batch['labels']).to(DEVICE)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0, iter = 1, Loss: 7.429810047149658\nEpoch 0, iter = 2, Loss: 6.215972423553467\nEpoch 0, iter = 3, Loss: 7.482779026031494\nEpoch 1, iter = 1, Loss: 7.552974224090576\nEpoch 1, iter = 2, Loss: 6.381274223327637\nEpoch 1, iter = 3, Loss: 7.307322978973389\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[7.042853832244873, 7.0805238087972]"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"evaluate(model, valid_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:24:22.439197Z","iopub.execute_input":"2025-06-09T14:24:22.439461Z","iopub.status.idle":"2025-06-09T14:24:22.472218Z","shell.execute_reply.started":"2025-06-09T14:24:22.439443Z","shell.execute_reply":"2025-06-09T14:24:22.471644Z"}},"outputs":[{"name":"stdout","text":"Validating\niter = 1, Loss: 6.406202793121338\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/4112800121.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  input_ids = torch.tensor(batch['input_ids']).to(DEVICE)\n/tmp/ipykernel_35/4112800121.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  attention_mask = torch.tensor(batch['attention_mask']).to(DEVICE)\n/tmp/ipykernel_35/4112800121.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(batch['labels']).to(DEVICE)\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"6.406202793121338"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"#save the model\nmodel.save_pretrained(\"/kaggle/working/Helsinki-NLP/opus-mt-ko-en-finetuning\")\n\n#save tokenizer\ntokenizer.save_pretrained(\"/kaggle/working/Helsinki-NLP/opus-mt-ko-en-finetuning-token\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:24:25.546373Z","iopub.execute_input":"2025-06-09T14:24:25.546982Z","iopub.status.idle":"2025-06-09T14:24:26.276828Z","shell.execute_reply.started":"2025-06-09T14:24:25.546962Z","shell.execute_reply":"2025-06-09T14:24:26.276224Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/Helsinki-NLP/opus-mt-ko-en-finetuning-token/tokenizer_config.json',\n '/kaggle/working/Helsinki-NLP/opus-mt-ko-en-finetuning-token/special_tokens_map.json',\n '/kaggle/working/Helsinki-NLP/opus-mt-ko-en-finetuning-token/vocab.json',\n '/kaggle/working/Helsinki-NLP/opus-mt-ko-en-finetuning-token/source.spm',\n '/kaggle/working/Helsinki-NLP/opus-mt-ko-en-finetuning-token/target.spm',\n '/kaggle/working/Helsinki-NLP/opus-mt-ko-en-finetuning-token/added_tokens.json')"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"#load the model\nfinetuned_model = MarianMTModel.from_pretrained(\"/kaggle/working/Helsinki-NLP/opus-mt-ko-en-finetuning\").to(DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:24:29.589505Z","iopub.execute_input":"2025-06-09T14:24:29.590190Z","iopub.status.idle":"2025-06-09T14:24:30.871937Z","shell.execute_reply.started":"2025-06-09T14:24:29.590168Z","shell.execute_reply":"2025-06-09T14:24:30.871390Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"src_text = [\"안녕하세요. 만나서 반갑습니다.\"]\ninputs = tokenizer(src_text, return_tensors=\"pt\", padding=True).to(DEVICE)\n\noutputs = finetuned_model.generate(**inputs)\n\ntranslation = tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:24:32.534148Z","iopub.execute_input":"2025-06-09T14:24:32.534424Z","iopub.status.idle":"2025-06-09T14:24:33.072930Z","shell.execute_reply.started":"2025-06-09T14:24:32.534405Z","shell.execute_reply":"2025-06-09T14:24:33.072358Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"translation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T14:24:35.801194Z","iopub.execute_input":"2025-06-09T14:24:35.801481Z","iopub.status.idle":"2025-06-09T14:24:35.807075Z","shell.execute_reply.started":"2025-06-09T14:24:35.801462Z","shell.execute_reply":"2025-06-09T14:24:35.806227Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'Hello. Nice to meet you.'"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}